##
## /etc/logstash/conf.d/10-api-access-filter.conf
## logstash grok patterns to parse nginx api_access.log
## 

##
## nginx log format 
## $time_iso8601 $msec $http_x_forwarded_for \
## $http_x_forwarded_proto $host $request_length \
## [$http_x_token] [$http_x_signature] [$upstream_http_x_brokerage] \
## [$upstream_http_x_cred_label] [$upstream_http_x_cred_type] $status \
## $body_bytes_sent $request_time $upstream_http_x_runtime \
## $request_method $uri $query_string [$http_user_agent]
##
filter {
  if [type] == "nginx" and [app_name] == "api" {
    grok {
      match => [
        'message', "%{TIMESTAMP_ISO8601:time_iso8601} %{DATA:msec} \[%{DATA:x_forwarded_for}\] %{DATA:x_forwarded_proto} %{NOTSPACE:hostname} %{DATA:request_length} \[%{DATA:authentication_token}\] \[%{DATA:x_token}\] \[%{DATA:x_signature}\] \[%{DATA:x_brokerage}\] \[%{DATA:x_cred_label}\] \[%{DATA:x_cred_type}\] %{NOTSPACE:status} %{DATA:body_bytes_sent} %{DATA:request_time} %{DATA:x_runtime} %{DATA:request_method} %{NOTSPACE:uri} %{DATA:query_string} \[%{DATA:user_agent}\]"
      ]
    }
    ## if this is present @timestamp will match time_iso8601
    date { match => [ "time_iso8601", "ISO8601" ] }

    ## varnish requests have multiple ip addresses in x_forwarded_for
    ## we need to split these and set the left most value to client_ip
    mutate {
      split     => { 'x_forwarded_for' => ',' }
      add_field => { 'client_ip' => "%{x_forwarded_for[0]}" }
      add_field => { 'endpoint' => "%{uri}" }
    }   
    ## ensure geoip can handle empty dashes, replace dash with load balancer ip
    ## geoip lookup will fail but it will not produce a logstash error
    mutate {
      gsub => [ 'client_ip', "^-$", '10.0.0.5' ]
    }
    ## now we can safely perform geoip lookups
    geoip {
      source    => 'client_ip'
      target    => 'geoip'
      add_field => [ "[geoip][coordinates]", "%{[geoip][longitude]}" ]
      add_field => [ "[geoip][coordinates]", "%{[geoip][latitude]}" ]      
    }
    mutate {   
      ## convert empty dashes in fields to string 'null'
      gsub => [ 'msec', "^-$", null ]
      gsub => [ 'x_forwarded_for', "^-$", null ]
      gsub => [ 'x_forwarded_proto', "^-$", null ]
      gsub => [ 'hostname', "^-$", null ]
      gsub => [ 'request_length', "^-$", null ]
      gsub => [ 'authentication_token', "^-$", null ]
      gsub => [ 'x_token', "^-$", null ]
      gsub => [ 'x_signature', "^-$", null ]
      gsub => [ 'x_brokerage', "^-$", null ]
      gsub => [ 'x_cred_label', "^-$", null ]
      gsub => [ 'x_cred_type', "^-$", null ]
      gsub => [ 'status', "^-$", null ]
      gsub => [ 'body_bytes_sent', "^-$", null ]
      gsub => [ 'request_time', "^-$", null ]
      gsub => [ 'x_runtime', "^-$", null ]
      gsub => [ 'request_method', "^-$", null ]
      gsub => [ 'uri', "^-$", null ]
      gsub => [ 'query_string', "^-$", null ]
      gsub => [ 'user_agent', "^-$", null ]
      ## geoip fields
      gsub => [ 'endpoint', "^-$", null ]
      gsub => [ 'geoip.city_name', "^-$", null ]
      gsub => [ 'geoip.continent_code', "^-$", null ]
      gsub => [ 'geoip.coordinates', "^-$", null ]
      gsub => [ 'geoip.country_code2', "^-$", null ]
      gsub => [ 'geoip.country_code3', "^-$", null ]
      gsub => [ 'geoip.country_name', "^-$", null ]
      gsub => [ 'geoip.dma_code', "^-$", null ]
      gsub => [ 'geoip.ip', "^-$", null ]
      gsub => [ 'geoip.latitude', "^-$", null ]
      gsub => [ 'geoip.location', "^-$", null ]
      gsub => [ 'geoip.longitude', "^-$", null ]
      gsub => [ 'geoip.postal_code', "^-$", null ]
      gsub => [ 'geoip.region_code', "^-$", null ]
      gsub => [ 'geoip.region_name', "^-$", null ]
      gsub => [ 'geoip.timezone', "^-$", null ]

      ## capture everything initially as sting, then type
      convert => { 'msec' => 'float' }
      convert => { 'request_length' => 'integer' }
      convert => { 'status' => 'integer' }
      convert => { 'body_bytes_sent' => 'integer' }
      convert => { 'request_time' => 'float' }
      convert => { 'x_runtime' => 'float' }
      ##
      ## The whole point of the 'endpoint' field is to provide a way to group
      ## similar requests to TEVO API endpoints together to allow us to easily
      ## create visualizations.  
      ##
      ## This is done by making a copy of the 'uri' field for each request into 
      ## a new field called 'endpoint'. We then perform transformations of 
      ## the string in the 'endpoint' field into generic strings.  For example:
      ##
      ## uri: /v9/venues/23345                    endpoint: /v9/venues/id
      ## uri: /v9/venues/1122344                  endpoint: /v9/venues/id
      ## uri: /v9/orders/23345/deliver_etickets   endpoint: /v9/orders/id/deliver_etickets
      ## uri: /v9/venues/yankees-stadium          endpoint: /v9/venues/name
      ## 
      ## This lets us easily construct lucene queries using the 'endpoint' field:
      ## 
      ## endpoint:/v9/venues/id
      ## endpoint:/v9/performers/name 
      ##     
      ## Many requests come in that are not valid endpoints.  For instance, we see
      ## requests for https://api.ticketevolution.com/ (GET /). This is not a valid 
      ## TEVO API endpoint, even though it is a valid request. So the question is,
      ## is the concept of an 'endpoint' valid for these requests?  What value is 
      ## appropriate for the 'endpoint' field in these cases? 
      ##
      ## Other bogus requests come in for images (favicon.ico for instance).  
      ## In these cases, the `endpoint` field ends up being a copy of the `uri` field:
      ##
      ## For each unique string that is not matched by any of the gsub patterns below,
      ## a unique value for to 'endpoints' fields gets created.  
      ##
      ## uri: /                                   endpoint: / 
      ## uri: /favicon.ico                        endpoint: /favicon.ico
      ##
      ## We should identify common invalid API requests and set the `endpoint` field to 
      ## something appropriate, such as the string 'na'.  This will quickly let us 
      ## exclude all invalid requests using the lucene query: 
      ##
      ## NOT endpoint:na.
      ##
      ## Otherwise, kibana users will have to exclude these uninteresting requests.
      ## The whole point of the `endpoint` field is to group and id valid TEVO API endpoints.
      ## As there is no '/' or 'favicon.ico' API endpoint, the endpoint field should reflect this.
      ##
      ##gsub => [ "endpoint", ".*\.(jpg|jpeg|png|gif|ico|txt)$", "NULL" ]
      ##gsub => [ "endpoint", "^/$", "NULL" ]
      ##
      ## There is also the consideration of proxied nginx requests.
      ## If someone makes a request to https://api.ticketevolution.com/configurations,
      ## nginx proxies this request to itself and prepends /v9/ to the request.
      ## These proxied requests will appear as two separate requests in the access logs.
      ##
      ## uri:/configurations/1234                  endpoint:/configurations/id
      ## uri:/v9/configurations/1234               endpoint:/v9/configurations/id

      ## match any category name except deleted endpoint
      gsub => [ 'endpoint', "/v9/categories/(?!deleted$)([a-zA-Z\-]|[0-9])*[a-zA-Z\-]+([a-zA-Z\-]|[0-9])*$", '/v9/categories/name' ]

      ## match any performer name except search and deleted
      gsub => [ 'endpoint', "/v9/performers/(?!(search|deleted)$)([a-zA-Z\-]|[0-9])*[a-zA-Z\-]+([a-zA-Z\-]|[0-9])*$", '/v9/performers/name' ]

      ## match any venue name except search and deleted
      gsub => [ 'endpoint', "/v9/venues/(?!(search|deleted)$)([a-zA-Z\-]|[0-9])*[a-zA-Z\-]+([a-zA-Z\-]|[0-9])*$", '/v9/venues/name' ]

      ## works for venues, configurations, users, tickets, ticket_groups
      ## /v9/(venues|configurations|users|tickets)/id
      gsub => [ 'endpoint', "/[0-9\-]+", '/id' ]
    }
  }
}
